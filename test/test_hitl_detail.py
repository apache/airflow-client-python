# coding: utf-8

"""
    Airflow API

    Airflow API. All endpoints located under ``/api/v2`` can be used safely, are stable and backward compatible. Endpoints located under ``/ui`` are dedicated to the UI and are subject to breaking change depending on the need of the frontend. Users should not rely on those but use the public ones instead.

    The version of the OpenAPI document: 2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from airflow_client.client.models.hitl_detail import HITLDetail

class TestHITLDetail(unittest.TestCase):
    """HITLDetail unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> HITLDetail:
        """Test HITLDetail
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `HITLDetail`
        """
        model = HITLDetail()
        if include_optional:
            return HITLDetail(
                assigned_users = [
                    airflow_client.client.models.hitl_user.HITLUser(
                        id = '', 
                        name = '', )
                    ],
                body = '',
                chosen_options = [
                    ''
                    ],
                created_at = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'),
                defaults = [
                    ''
                    ],
                multiple = True,
                options = [
                    ''
                    ],
                params = airflow_client.client.models.params.Params(),
                params_input = airflow_client.client.models.params_input.Params Input(),
                responded_at = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'),
                responded_by_user = airflow_client.client.models.hitl_user.HITLUser(
                    id = '', 
                    name = '', ),
                response_received = True,
                subject = '',
                task_instance = airflow_client.client.models.task_instance_response.TaskInstanceResponse(
                    dag_display_name = '', 
                    dag_id = '', 
                    dag_run_id = '', 
                    dag_version = airflow_client.client.models.dag_version_response.DagVersionResponse(
                        bundle_name = '', 
                        bundle_url = '', 
                        bundle_version = '', 
                        created_at = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        dag_display_name = '', 
                        dag_id = '', 
                        id = '', 
                        version_number = 56, ), 
                    duration = 1.337, 
                    end_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    executor = '', 
                    executor_config = '', 
                    hostname = '', 
                    id = '', 
                    logical_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    map_index = 56, 
                    max_tries = 56, 
                    note = '', 
                    operator = '', 
                    operator_name = '', 
                    pid = 56, 
                    pool = '', 
                    pool_slots = 56, 
                    priority_weight = 56, 
                    queue = '', 
                    queued_when = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    rendered_fields = airflow_client.client.models.rendered_fields.Rendered Fields(), 
                    rendered_map_index = '', 
                    run_after = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    scheduled_when = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    start_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    state = 'removed', 
                    task_display_name = '', 
                    task_id = '', 
                    trigger = airflow_client.client.models.trigger_response.TriggerResponse(
                        classpath = '', 
                        created_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        id = 56, 
                        kwargs = '', 
                        triggerer_id = 56, ), 
                    triggerer_job = airflow_client.client.models.job_response.JobResponse(
                        dag_display_name = '', 
                        dag_id = '', 
                        end_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        executor_class = '', 
                        hostname = '', 
                        id = 56, 
                        job_type = '', 
                        latest_heartbeat = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        start_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        unixname = '', ), 
                    try_number = 56, 
                    unixname = '', )
            )
        else:
            return HITLDetail(
                created_at = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'),
                options = [
                    ''
                    ],
                subject = '',
                task_instance = airflow_client.client.models.task_instance_response.TaskInstanceResponse(
                    dag_display_name = '', 
                    dag_id = '', 
                    dag_run_id = '', 
                    dag_version = airflow_client.client.models.dag_version_response.DagVersionResponse(
                        bundle_name = '', 
                        bundle_url = '', 
                        bundle_version = '', 
                        created_at = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        dag_display_name = '', 
                        dag_id = '', 
                        id = '', 
                        version_number = 56, ), 
                    duration = 1.337, 
                    end_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    executor = '', 
                    executor_config = '', 
                    hostname = '', 
                    id = '', 
                    logical_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    map_index = 56, 
                    max_tries = 56, 
                    note = '', 
                    operator = '', 
                    operator_name = '', 
                    pid = 56, 
                    pool = '', 
                    pool_slots = 56, 
                    priority_weight = 56, 
                    queue = '', 
                    queued_when = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    rendered_fields = airflow_client.client.models.rendered_fields.Rendered Fields(), 
                    rendered_map_index = '', 
                    run_after = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    scheduled_when = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    start_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    state = 'removed', 
                    task_display_name = '', 
                    task_id = '', 
                    trigger = airflow_client.client.models.trigger_response.TriggerResponse(
                        classpath = '', 
                        created_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        id = 56, 
                        kwargs = '', 
                        triggerer_id = 56, ), 
                    triggerer_job = airflow_client.client.models.job_response.JobResponse(
                        dag_display_name = '', 
                        dag_id = '', 
                        end_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        executor_class = '', 
                        hostname = '', 
                        id = 56, 
                        job_type = '', 
                        latest_heartbeat = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        start_date = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        unixname = '', ), 
                    try_number = 56, 
                    unixname = '', ),
        )
        """

    def testHITLDetail(self):
        """Test HITLDetail"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
